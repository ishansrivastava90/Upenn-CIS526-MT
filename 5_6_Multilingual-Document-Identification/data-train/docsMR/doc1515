Chiński pokój, argument chińskiego pokoju – amerykańskiego filozofa Johna Searle'a i przedstawiony w jego pracy z sztucznej inteligencji. U podstaw eksperymentu stoi niezgodność między syntaksą a semantyką. Załóżmy, że skonstruowaliśmy informację wyjściową. Załóżmy, że ten zadanie w sposób tak przekonujący, że łatwo przechodzi sztucznej inteligencji wyciągają stąd wniosek, że komputer rozumie chiński, tak jak człowiek. W ciągu ostatnich dwóch dekad dwudziestego stulecia argument chińskiego pokoju był przedmiotem wielu dyskusji. W styczniu 1990 popularny periodyk Scientific American przedstawił debatę na ogólnym forum naukowym. Searle włączył argument chińskiego pokoju w swą wypowiedź Is the Brain's Mind a Computer Program?. Odpowiedzią na jego wkład był artykuł Could a Machine Think? napisany przez Paula i Patricię Churchland. Wkrótce potem opublikowana została dyskusja Searle'a o chińskim pokoju z innym wiodącym filozofem umysłu, Jerrym Fodorem. Sercem argumentu jest wyobrażona ludzka symulacja Maszyny Turinga. Człowiek w chińskim pokoju przestrzega angielskich instrukcji dla manipulowania chińskimi znakami, gdzie komputer 'przestrzega' programu napisanego w języku obliczeniowym. Człowiek produkuje podobieństwo rozumienia chińskiego przez przestrzeganie instrukcji manipulacji symbolami, ale nie dochodzi przez to do rozumienia chińskiego. Ponieważ komputer robi to, co robi człowiek – jedynie manipuluje symbolami na podstawie ich syntaksy – żaden komputer nie może dojść do istotnego rozumienia języka chińskiego, wyłącznie przez przestrzeganie programu. Ten ściśle oparty na scenariuszu chińskiego pokoju argument jest skierowany przeciw stanowisku nazwanemu przez Searla „mocną AI”. Mocna AI jest poglądem, że odpowiednio zaprogramowane programy) mogą rozumieć naturalny język i mieć inne zdolności mentalne podobne do ludzkich, których możliwości one naśladują. Nawiązując do mocnej AI, psychologii, lingwistyce i po części w innych obszarach, ponieważ mogą symulować zdolności mentalne. Ale słaba AI nie twierdzi, że inteligentne. Argument chińskiego pokoju nie jest skierowany w słabą AI, ani nie ma na celu pokazania, że maszyny nie mogą myśleć - Searle powiada, że ludzki maszyną i mimo to ma zdolność myślenia. Argument ten ma podważać pogląd, że formalne wyliczenia na symbolach produkują myśl. Te dwa wnioski ukazują, że mocna AI jest fałszywa. Jądrem argumentu Searle'a jest rozróżnienie między syntaksą i semantyką. Pokój jest w stanie przestawiać litery zgodnie z książką reguł. To znaczy, że zachowanie pokoju może być opisane jako postępujące z regułami syntaktycznymi. Ale w stanowisku Searla on sam nie zna znaczenia tego co robi. To znaczy, że nie ma treści semantycznej. Znaki nie są nawet symbolami, bo nie są interpretowane na żadnym etapie procesu. Searle opisuje tę wersję jako „wyjątkowo byle jaka”. Odbyła się poważna debata na temat słuszności tego argumentu, która skupiała się na różnych sposobach, jakimi założenia mogą być wypróbowane. Każdy może przeczytać założenie 3. jako mówiące, że programy komputerowe mają zawartość syntaktyczną, ale nie semantyczną.  Założenia 2. 3. i 4. prowadzą do wniosku 1. To zaś skłania do debaty o początku zawartości semantycznej programu komputera. Odpowiedzią Searla jest stwierdzenie, że ktoś może w zasadzie zapamiętać książkę reguł, a wtedy będzie mógł reagować jakby rozumiał chiński, ale nadal będzie tylko postępował według zbioru reguł, bez rozumienia znaczenia symboli, jakimi manipuluje. To prowadzi do interesującego problemu osoby, która może płynnie rozmawiać po chińsku 'nie znając' tego języka. W Consciousness Explained Daniel C. Dennett podaje rozszerzenie odpowiedzi dla systemu, którego podstawa polega na tym, że przykład Searle'a ma na celu wprowadzenie w błąd wyobrażającego sobie. Zostajemy poproszeni o wyobrażenie sobie maszyny, która przeszłaby test Turinga przez zwykle manipulowanie symbolami. Jest wysoce nieprawdopodobne, że taki zgrubny system przeszedłby test Turinga. Jeżeli system byłby rozszerzony, żeby włączyć rozmaite systemy detekcji by doprowadzić do spójnych odpowiedzi i byłby przepisany na wielka maszynę równoległą zamiast na szeregową maszynę Von Neumanna szybko byłoby bardziej "oczywiste" ze nie ma świadomego postrzegania. Dla testu Turinga operator w chińskim pokoju musiałby być wspomagany przez wielka liczbę pomocników, albo ilość czasu danego na wyprodukowanie odpowiedzi na nawet najbardziej podstawowe pytania byłaby bardzo duża - wiele milionów lub przypuszczalnie miliardów lat. Uwaga zrobiona przez Dennetta jest taka, że przez wyobrażenie "tak, to jest przekonywające używać tablicy wyszukiwania do wejścia i dać wyjście i przejść test Turinga" zaburzamy złożoność istotnie zaangażowaną w taki sposób, że to rzeczywiście wydaje się "oczywiste", iż ten system nie może być świadomy. Jednak taki system jest nieodpowiedni. Jakikolwiek rzeczywisty system zdolny do istotnego spełnienia koniecznych warunków byłby tak złożony że wcale nie byłoby "oczywiste", iż brakuje mu zrozumienia chińskiego. On musiałby z pewnością porównywać koncepcje i formułować możliwe odpowiedzi, usuwać opcje itd., aż wypadłby albo jak powolna i całkowita analiza semantyki wejścia, albo zachowywałby się jak każdy inny mówiący po chińsku. Dopóki nie musimy dowodzić, że miliard mówiących chińskim ludzi jest czymś więcej niż siecią równoległą symulującą maszynę Von Neumanna na wyjściu musimy zaakceptować, że chiński pokój jest tak samo mówiący po chińsku jak każdy inny Chińczyk. Załóżmy, że program realizujący książkę reguł symuluje dokładnie interakcje w mózgu Chińczyka. Wówczas z pewnością program rozumiałby chiński? Searle odpowiada, że taka symulacja nie odtworzy ważnych cech mózgu - jego wyjaśniających i intencjonalnych stanów. Ale co, jeżeli mózgowa symulacja była powiązana do świata w taki sposób ze ma przyczynowe władzę rzeczywistego mózgu - przypuszczalnie połączonego do robota typu opisanego powyżej? Wtedy na pewno byłaby zdolna myśleć. Searle zgadza się, że jest to w podstawie możliwe, aby stworzyć sztuczną inteligencję, ale wskazuje, że taka maszyna miałaby przyczynową władzę mózgu. To byłoby więcej niż zwykły program komputera.