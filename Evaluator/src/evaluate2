#!/usr/bin/env python

import argparse
import sys, os
from itertools import islice
from collections import namedtuple
from collections import OrderedDict

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'util'))
import generateSkipGrams

""" Generator for the sentences """
def sentences(opts):
    with open(opts.input) as f:
        for pair in f:
            yield [sentence.strip().split() for sentence in pair.split(' ||| ')]


""" Matches common words in lists and
    return counts
"""
def word_matches(h, ref_set):
    return sum(1 for word in h if word in ref_set )


def score_partial(h, all_grams):
    #sys.stderr.write("Calculating score partial for sen - %s\n" %h)
    partial_score = 0
    tot_ngrams = 0

    for i, n_grams in enumerate(all_grams):
        #print n_grams
        for gram in n_grams:
            for k in range(0,i+1):
                if gram[k] in h:
                    partial_score += 1
                    break
        tot_ngrams += len(n_grams)

    return float(partial_score)/tot_ngrams

def score_full(h, all_grams):
    #sys.stderr.write("Calculating score full for sen - %s\n" %h)
    full_score = 0
    tot_ngrams = 0

    for i, n_grams in enumerate(all_grams):
        #print n_grams
        for gram in n_grams:
            isMatched = True
            for k in range(0,i+1):
                if gram[k] not in h:
                    isMatched = False
                    break
            if isMatched:
                full_score += 1

        tot_ngrams += len(n_grams)

    return float(full_score)/tot_ngrams


def score_ordered(h, all_grams):
    #sys.stderr.write("Calculating score Ordered for sen - %s\n" %h)
    ord_score = 0
    tot_ngrams = 0

    for i, n_grams in enumerate(all_grams):
        #print n_grams
        for gram in n_grams:
            isMatched = True
            ind = 0
            for k in range(0,i+1):
                if gram[k] not in h or h.index(gram[k]) < ind:
                    isMatched = False
                    break
                ind = h.index(gram[k])
            if isMatched:
                ord_score += 1
        tot_ngrams += len(n_grams)


    return float(ord_score)/tot_ngrams



def score(l1, l2):
    return 1 if l1 > l2 else ( -1 if l1 < l2 else 0 )


def generate_all_grams(ref_set):
    # Generating 2 skip unigrams
    grams1 = generateSkipGrams.gen_k_skip_ngrams(ref_set, 2, 1)

    # Generating 2 skip bi-grams
    grams2 = generateSkipGrams.gen_k_skip_ngrams(ref_set, 2, 2)

    # Generating 1 skip tri-grams
    grams3 = generateSkipGrams.gen_k_skip_ngrams(ref_set, 1, 3)

    # Generating 1 skip 4-grams
    grams4 = generateSkipGrams.gen_k_skip_ngrams(ref_set, 1, 4)

    all_grams_tuple = namedtuple("all_grams","grams1, grams2, grams3, grams4")
    all_grams = all_grams_tuple(grams1, grams2, grams3, grams4)

    return all_grams

"""
    Evaluates the score using lvalues for both translations
    using METEOR metric
"""

def evaluate(opts):

    for h1, h2, ref in islice(sentences(opts), opts.num_sentences):

        ref_set = list(OrderedDict.fromkeys(ref))

        # Generating all-grams ( 1,2,3,4 - skip grams )
        all_grams = generate_all_grams(ref_set)

        score1 = float(score_partial(h1, all_grams) + score_full(h1, all_grams) + score_ordered(h1, all_grams))/3
        score2 = float(score_partial(h2, all_grams) + score_full(h2, all_grams) + score_ordered(h2, all_grams))/3

        print score(score1, score2)


    return

""" Main driver function """
if __name__=="__main__":
    # Argument Parser for the script
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input', default='../data/hyp1-hyp2-ref', help='input file (default ../data/hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=sys.maxint, type=int, help='Number of hypothesis pairs to evaluate')
    parser.add_argument('-a', '--alpha', default=0.5, type=float, help='Alpha values for precision and recall')
    opts = parser.parse_args()

    evaluate(opts)